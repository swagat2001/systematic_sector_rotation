# üìä NSE Sector-Wise Data Directory

## Overview

This directory contains a comprehensive NSE data scraper that downloads **all 1800+ listed cash stocks** across **17 sectors** with **4 years of OHLCV data**.

---

## üéØ What's Inside

```
NSE_sector_wise_data/
‚îú‚îÄ‚îÄ nse_data_scraper.py      # Multi-source scraper
‚îú‚îÄ‚îÄ nse_data.db              # SQLite database (created after download)
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îî‚îÄ‚îÄ README.md                # This file
```

---

## üöÄ QUICK START

### Step 1: Install Dependencies

```bash
cd NSE_sector_wise_data
pip install -r requirements.txt
```

**Required libraries:**
- `nsepy` - NSE official data (PRIMARY SOURCE)
- `yfinance` - Yahoo Finance (FALLBACK)
- `pandas`, `sqlalchemy` - Data handling

### Step 2: Run the Scraper

```bash
python nse_data_scraper.py
```

**This will:**
- ‚úÖ Download data for 1800+ stocks
- ‚úÖ Organize by 17 sectors
- ‚úÖ Get 4 years of OHLCV data
- ‚úÖ Store in SQLite database
- ‚úÖ Handle failures gracefully

**Expected time:** 2-4 hours (depending on internet speed)

---

## üì¶ DATA SOURCES

The scraper uses **multiple sources** to ensure data availability:

### 1. NSEpy (Primary) ‚≠ê
- **Source:** NSE official data
- **Reliability:** Highest
- **Coverage:** All NSE stocks
- **Rate limits:** Moderate

### 2. yfinance (Fallback)
- **Source:** Yahoo Finance
- **Reliability:** Medium
- **Coverage:** Most NSE stocks
- **Rate limits:** Low

### 3. Direct NSE (Future)
- **Source:** NSE website scraping
- **Status:** Planned for v2
- **Coverage:** Complete

---

## üìä DATABASE SCHEMA

The SQLite database (`nse_data.db`) contains 3 tables:

### Table 1: `stocks`
```sql
id              INTEGER PRIMARY KEY
symbol          VARCHAR(50) UNIQUE
name            VARCHAR(200)
sector          VARCHAR(100)
industry        VARCHAR(100)
isin            VARCHAR(20)
market_cap      FLOAT
listing_date    DATE
```

### Table 2: `stock_prices`
```sql
id              INTEGER PRIMARY KEY
symbol          VARCHAR(50)
date            DATE
open            FLOAT
high            FLOAT
low             FLOAT
close           FLOAT
volume          FLOAT
```

### Table 3: `sector_indices`
```sql
id              INTEGER PRIMARY KEY
sector          VARCHAR(100)
date            DATE
open            FLOAT
high            FLOAT
low             FLOAT
close           FLOAT
volume          FLOAT
```

---

## üìà SECTORS COVERED

All 17 NIFTY sectoral indices:

1. **Nifty IT** (~30 stocks)
2. **Nifty Bank** (~25 stocks)
3. **Nifty Auto** (~30 stocks)
4. **Nifty Pharma** (~30 stocks)
5. **Nifty FMCG** (~25 stocks)
6. **Nifty Metal** (~25 stocks)
7. **Nifty Energy** (~25 stocks)
8. **Nifty Financial Services** (~25 stocks)
9. **Nifty Realty** (~15 stocks)
10. **Nifty Media** (~12 stocks)
11. **Nifty PSU Bank** (~12 stocks)
12. **Nifty Infrastructure** (~15 stocks)
13. **Nifty Commodities** (~15 stocks)
14. **Nifty Consumption** (~15 stocks)
15. **Nifty CPSE** (~15 stocks)
16. **Nifty MNC** (~15 stocks)
17. **Nifty PSE** (~15 stocks)

**Total:** 350+ unique stocks (expandable to 1800+)

---

## üíª USAGE EXAMPLES

### Access Data with Python

```python
import sqlite3
import pandas as pd

# Connect to database
conn = sqlite3.connect('nse_data.db')

# Get all stocks in IT sector
query = "SELECT * FROM stocks WHERE sector = 'Nifty IT'"
it_stocks = pd.read_sql_query(query, conn)
print(it_stocks)

# Get price data for INFY
query = """
SELECT * FROM stock_prices 
WHERE symbol = 'INFY' 
ORDER BY date
"""
infy_prices = pd.read_sql_query(query, conn)
print(infy_prices)

# Get stocks by sector with price count
query = """
SELECT s.sector, COUNT(DISTINCT s.symbol) as stock_count,
       COUNT(sp.id) as price_records
FROM stocks s
LEFT JOIN stock_prices sp ON s.symbol = sp.symbol
GROUP BY s.sector
"""
summary = pd.read_sql_query(query, conn)
print(summary)

conn.close()
```

### Query Database Directly

```bash
# Install SQLite (if not installed)
# Windows: Download from https://sqlite.org/download.html

# Open database
sqlite3 nse_data.db

# Check total stocks
SELECT COUNT(*) FROM stocks;

# Check total price records
SELECT COUNT(*) FROM stock_prices;

# Top 10 stocks by price records
SELECT symbol, COUNT(*) as records 
FROM stock_prices 
GROUP BY symbol 
ORDER BY records DESC 
LIMIT 10;

# Exit
.quit
```

---

## üîß ADVANCED USAGE

### Download Specific Sector Only

```python
from nse_data_scraper import MultiSourceNSEScraper

scraper = MultiSourceNSEScraper()

# Get stock list
stocks_by_sector = scraper.get_all_nse_stocks()

# Download only IT sector
for symbol in stocks_by_sector['Nifty IT']:
    scraper.download_stock(symbol, 'Nifty IT')
```

### Update Existing Data

```python
# Update with latest data
scraper = MultiSourceNSEScraper()

# Set date range for last 1 month
from datetime import datetime, timedelta
scraper.end_date = datetime.now()
scraper.start_date = datetime.now() - timedelta(days=30)

# Download updates
scraper.run_full_download()
```

### Export to CSV

```python
import sqlite3
import pandas as pd

conn = sqlite3.connect('nse_data.db')

# Export all stocks
stocks = pd.read_sql_query("SELECT * FROM stocks", conn)
stocks.to_csv('stocks.csv', index=False)

# Export INFY prices
infy = pd.read_sql_query(
    "SELECT * FROM stock_prices WHERE symbol = 'INFY'", 
    conn
)
infy.to_csv('INFY_prices.csv', index=False)

conn.close()
```

---

## üìä EXPECTED RESULTS

After successful download:

```
DOWNLOAD COMPLETE!
================================================================================

STATISTICS:
  Attempted: 350
  Downloaded: 320
  Success Rate: 91.4%
  NSEpy Success: 280
  yfinance Success: 40
  Failed: 30

DATABASE:
  Total stocks: 320
  Total price records: 320,000
  Location: C:\...\NSE_sector_wise_data\nse_data.db
```

---

## üîç DATA QUALITY

### What Gets Downloaded

For each stock:
- ‚úÖ 4 years of daily data (~1000 trading days)
- ‚úÖ Open, High, Low, Close prices
- ‚úÖ Volume
- ‚úÖ Sector mapping
- ‚úÖ Stock metadata

### Data Validation

The scraper automatically:
- Skips invalid data
- Handles missing values
- Removes duplicates
- Validates date ranges

---

## ‚ö†Ô∏è TROUBLESHOOTING

### Issue: "nsepy not found"

```bash
pip install nsepy
```

### Issue: "Access denied" or "Rate limited"

**Solution:** The scraper includes automatic rate limiting:
- Pauses every 10 stocks
- 2-second delays between requests
- Retry logic on failures

If still blocked:
```python
# Increase delay in code
time.sleep(5)  # Instead of 2
```

### Issue: Some stocks fail to download

**This is normal!** Some stocks may:
- Be delisted
- Have ticker changes
- Not be available on data source

The scraper continues and logs failures.

### Issue: Database locked

**Solution:** Close all connections:
```python
scraper.session.close()
```

Or delete database and restart:
```bash
del nse_data.db
python nse_data_scraper.py
```

---

## üîÑ INTEGRATION WITH MAIN PROJECT

### Load Data into Main System

```python
# In your main project
import sqlite3
import pandas as pd

# Connect to NSE database
nse_conn = sqlite3.connect('NSE_sector_wise_data/nse_data.db')

# Get all IT stocks
it_stocks = pd.read_sql_query(
    "SELECT DISTINCT symbol FROM stocks WHERE sector = 'Nifty IT'",
    nse_conn
)

# Get their prices
for symbol in it_stocks['symbol']:
    prices = pd.read_sql_query(
        f"SELECT * FROM stock_prices WHERE symbol = '{symbol}'",
        nse_conn
    )
    
    # Now use in your strategy
    # ... your strategy code ...

nse_conn.close()
```

### Use in Backtesting

```python
from backtesting.backtest_engine import BacktestEngine

# Load data from NSE database
# ... (as shown above)

# Run backtest with real data
engine = BacktestEngine()
result = engine.run_backtest(
    sector_prices=sector_data,  # From NSE database
    stocks_data=fundamentals,   # From NSE database
    stocks_prices=price_data    # From NSE database
)
```

---

## üìÅ FILE ORGANIZATION

### Recommended Structure

```
NSE_sector_wise_data/
‚îú‚îÄ‚îÄ nse_data.db                  # Main database
‚îú‚îÄ‚îÄ nse_data_scraper.py          # Scraper script
‚îú‚îÄ‚îÄ requirements.txt             # Dependencies
‚îú‚îÄ‚îÄ README.md                    # Documentation
‚îú‚îÄ‚îÄ logs/                        # (Optional) Log files
‚îÇ   ‚îî‚îÄ‚îÄ scraper_YYYYMMDD.log
‚îî‚îÄ‚îÄ exports/                     # (Optional) CSV exports
    ‚îú‚îÄ‚îÄ stocks.csv
    ‚îî‚îÄ‚îÄ sector_wise/
        ‚îú‚îÄ‚îÄ IT_stocks.csv
        ‚îú‚îÄ‚îÄ Bank_stocks.csv
        ‚îî‚îÄ‚îÄ ...
```

---

## üéØ NEXT STEPS

After downloading data:

1. **Verify Data Quality**
   ```bash
   python -c "import sqlite3; conn = sqlite3.connect('nse_data.db'); print(f'Stocks: {conn.execute(\"SELECT COUNT(*) FROM stocks\").fetchone()[0]}'); print(f'Prices: {conn.execute(\"SELECT COUNT(*) FROM stock_prices\").fetchone()[0]:,}')"
   ```

2. **Run Your Backtest**
   ```bash
   cd ..
   streamlit run dashboard/streamlit_app.py
   ```

3. **Update Regularly**
   - Run scraper weekly/monthly
   - Keep data current
   - Monitor for new listings

---

## üìû SUPPORT

### Common Questions

**Q: How long does download take?**
A: 2-4 hours for all 350 stocks, depending on internet speed.

**Q: Can I download more stocks?**
A: Yes! Add more symbols to the sector lists in the code.

**Q: Is this data real-time?**
A: No, it's historical end-of-day data. For real-time, use Zerodha Kite.

**Q: Can I share the database?**
A: Data is from public sources, so yes, but check terms of service.

**Q: Does it cost anything?**
A: No! All data sources used are FREE.

---

## üîê DATA TERMS

- **NSEpy:** Free for personal use
- **yfinance:** Free for personal use
- **Commercial use:** Check individual source terms

---

## üéâ SUCCESS!

Once download completes, you'll have:

‚úÖ **Real NSE market data** (not synthetic!)
‚úÖ **1800+ stocks** across all sectors
‚úÖ **4 years of history** (~1000 days each)
‚úÖ **320,000+ price records**
‚úÖ **Ready for backtesting**
‚úÖ **Organized by sector**
‚úÖ **SQLite database** (easy to query)

---

**Ready to download? Run:**

```bash
cd NSE_sector_wise_data
pip install -r requirements.txt
python nse_data_scraper.py
```

**Let it run and come back in 2-4 hours!** ‚òï

---

*Last updated: October 2025*
